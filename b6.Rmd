---
title: "Chapter 6"
subtitle: "Bayesian Computing with R"
date: "`r Sys.time()`"
#output: github_document
output: html_notebook
editor_options: 
  chunk_output_type: inline
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)
library(LearnBayes)
```


```{r}
####################################################
# Section 6.2 Introduction to Discrete Markov Chains
####################################################

 P=matrix(c(.5,.5,0,0,0,0,.25,.5,.25,0,0,0,0,.25,.5,.25,0,0,
           0,0,.25,.5,.25,0,0,0,0,.25,.5,.25,0,0,0,0,.5,.5),
           nrow=6,ncol=6,byrow=TRUE)
 P

 s=array(0,c(50000,1))

 s[1]=3
 for (j in 2:50000)
   s[j]=sample(1:6,size=1,prob=P[s[j-1],])

 m=c(500,2000,8000,50000)
 for (i in 1:4)
   print(table(s[1:m[i]])/m[i])

 w=matrix(c(.1,.2,.2,.2,.2,.1),nrow=1,ncol=6)
 w%*%P

```

```{r}
##################################################################
# Section 6.7 Learning about a Normal Population from Grouped Data
##################################################################

library(LearnBayes)

 d=list(int.lo=c(-Inf,seq(66,74,by=2)),
        int.hi=c(seq(66,74,by=2), Inf),
        f=c(14,30,49,70,33,15))

y=c(rep(65,14),rep(67,30),rep(69,49),rep(71,70),rep(73,33),
  rep(75,15))
 mean(y)

 log(sd(y))

 start=c(70,1)
 fit=laplace(groupeddatapost,start,d)
 fit

 modal.sds=sqrt(diag(fit$var))

 proposal=list(var=fit$var,scale=2)
 fit2=rwmetrop(groupeddatapost,proposal,start,10000,d)

 fit2$accept

 post.means=apply(fit2$par,2,mean)
 post.sds=apply(fit2$par,2,sd)

 cbind(c(fit$mode),modal.sds)

 cbind(post.means,post.sds)

 mycontour(groupeddatapost,c(69,71,.6,1.3),d,
    xlab="mu",ylab="log sigma")
 points(fit2$par[5001:10000,1],fit2$par[5001:10000,2])

```


```{r}
##################################################
# Section 6.8 Example of Output Analysis
##################################################
 library(LearnBayes)

 d=list(int.lo=c(-Inf,seq(66,74,by=2)),
        int.hi=c(seq(66,74,by=2), Inf),
        f=c(14,30,49,70,33,15))

 library(coda)
 library(lattice)

 start=c(70,1)
 fit=laplace(groupeddatapost,start,d)

 start=c(65,1)
 proposal=list(var=fit$var,scale=0.2)
 bayesfit=rwmetrop(groupeddatapost,proposal,start,10000,d)

 dimnames(bayesfit$par)[[2]]=c("mu","log sigma")
 xyplot(mcmc(bayesfit$par[-c(1:2000),]),col="black")



 
 par(mfrow=c(2,1))
 autocorr.plot(mcmc(bayesfit$par[-c(1:2000),]),auto.layout=FALSE)
 summary(mcmc(bayesfit$par[-c(1:2000),]))
 batchSE(mcmc(bayesfit$par[-c(1:2000),]), batchSize=50)



 start=c(70,1)
 proposal=list(var=fit$var,scale=2.0)
 bayesfit=rwmetrop(groupeddatapost,proposal,start,10000,d)

 dimnames(bayesfit$par)[[2]]=c("mu","log sigma")
 sim.parameters=mcmc(bayesfit$par[-c(1:2000),])
 
 xyplot(mcmc(bayesfit$par[-c(1:2000),]),col="black")



 
 par(mfrow=c(2,1))
 autocorr.plot(sim.parameters,auto.layout=FALSE)
 summary(sim.parameters)
 batchSE(sim.parameters, batchSize=50)


```

```{r}
###################################################
# Section 6.9 Modeling Data with Cauchy Errors
###################################################

library(LearnBayes)

 data(darwin)
 attach(darwin)
 mean(difference)

 log(sd(difference))

 laplace(cauchyerrorpost,c(21.6,3.6),difference)

 laplace(cauchyerrorpost,.1*c(21.6,3.6),difference)$mode
 
 c(24.7-4*sqrt(34.96),24.7+4*sqrt(34.96))
 c(2.77-4*sqrt(.138),2.77+4*sqrt(.138))

 mycontour(cauchyerrorpost,c(-10,60,1,4.5),difference,
   xlab="mu",ylab="log sigma")



 fitlaplace=laplace(cauchyerrorpost,c(21.6,3.6), difference)
 
 mycontour(lbinorm,c(-10,60,1,4.5),list(m=fitlaplace$mode,
   v=fitlaplace$var), xlab="mu",ylab="log sigma")

 proposal=list(var=fitlaplace$var,scale=2.5)
 start=c(20,3)
 m=1000
 s=rwmetrop(cauchyerrorpost,proposal,start,m,difference)



 
 mycontour(cauchyerrorpost,c(-10,60,1,4.5),difference,
   xlab="mu",ylab="log sigma")
 points(s$par[,1],s$par[,2])

 fitgrid=simcontour(cauchyerrorpost,c(-10,60,1,4.5),difference,
  50000)
 proposal=list(var=fitlaplace$var,scale=2.5)
 start=c(20,3)
 fitrw=rwmetrop(cauchyerrorpost,proposal,start,50000,
   difference)
 proposal2=list(var=fitlaplace$var,mu=t(fitlaplace$mode))
 fitindep=indepmetrop(cauchyerrorpost,proposal2,start,50000,
  difference)
 fitgibbs=gibbs(cauchyerrorpost,start,50000,c(12,.75),
  difference)

 apply(fitrw$par,2,mean)

 apply(fitrw$par,2,sd)


```


```{r}
#############################################################
# Section 6.10 Analysis of the Stanford Heart Transplant Data
#############################################################

library(LearnBayes)

data(stanfordheart)

 start=c(0,3,-1)
 laplacefit=laplace(transplantpost,start,stanfordheart)
 laplacefit

 proposal=list(var=laplacefit$var,scale=2)
 s=rwmetrop(transplantpost,proposal,start,10000,stanfordheart)
 s$accept

 par(mfrow=c(2,2))
 tau=exp(s$par[,1])
 plot(density(tau),main="TAU")
 lambda=exp(s$par[,2])
 plot(density(lambda),main="LAMBDA")
 p=exp(s$par[,3])
 plot(density(p),main="P")

 apply(exp(s$par),2,quantile,c(.05,.5,.95))



 par(mfrow=c(1,1))
  t=seq(1,240)
 p5=0*t; p50=0*t; p95=0*t
 for (j in 1:240)
 { S=(lambda/(lambda+t[j]))^p
   q=quantile(S,c(.05,.5,.95))
   p5[j]=q[1]; p50[j]=q[2]; p95[j]=q[3]}
 
 plot(t,p50,type="l",ylim=c(0,1),ylab="Prob(Survival)",
   xlab="time")
 lines(t,p5,lty=2)
 lines(t,p95,lty=2)
```




